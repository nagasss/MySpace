# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
import pandas as pd
shoes_df = pd.read_csv('shoes_total_reviews_urlclean.csv')
shoes_df.head()
shoes_df.info()
```
ðŸ“Œ 1. ë¦¬ë·° ê´€ë ¨ ì»¬ëŸ¼
----
grade	ë¦¬ë·° í‰ì  (ì˜ˆ: 1~5ì )
review_contents	ë¦¬ë·° í…ìŠ¤íŠ¸ ë‚´ìš©
useful_count	ë¦¬ë·°ê°€ ìœ ìš©í•˜ë‹¤ê³  í‰ê°€ëœ íšŸìˆ˜ (ì¢‹ì•„ìš” ìˆ˜)


ðŸ“Œ 2. ìƒí’ˆ ê´€ë ¨ ì»¬ëŸ¼
----
site_name	ìƒí’ˆì´ ë“±ë¡ëœ ì‚¬ì´íŠ¸ ì´ë¦„
brand_name	ë¸Œëžœë“œëª… (ì˜ˆ: Nike, Adidas)
inter_cat	ìƒí’ˆì˜ ë‚´ë¶€ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: ëŸ¬ë‹í™”, ë†êµ¬í™”)
product_id	ì œí’ˆ ê³ ìœ  ID
product_name	ì œí’ˆëª… (ì˜ˆ: "Nike Air Max")
product_color	ì œí’ˆ ìƒ‰ìƒ (ì˜ˆ: "Red", "Black")
product_gender	ì œí’ˆ ì„±ë³„ (ì˜ˆ: ë‚¨ì„±/ì—¬ì„±/ìœ ë‹ˆì„¹ìŠ¤)
product_price	ì œí’ˆ ê°€ê²©
product_url	ì œí’ˆ ìƒì„¸ íŽ˜ì´ì§€ URL


ðŸ“Œ 3. êµ¬ë§¤ìž ì •ë³´ ê´€ë ¨ ì»¬ëŸ¼
----
buyer_id	êµ¬ë§¤ìž ID
buyer_size	êµ¬ë§¤ìžì˜ ì‹ ë°œ ì‚¬ì´ì¦ˆ
buy_size	êµ¬ë§¤í•œ ì‹ ë°œ ì‚¬ì´ì¦ˆ
buyer_height	êµ¬ë§¤ìžì˜ í‚¤
buyer_weight	êµ¬ë§¤ìžì˜ ëª¸ë¬´ê²Œ
buyer_daily_size	êµ¬ë§¤ìžê°€ í‰ì†Œ ì‹ ëŠ” ì‹ ë°œ ì‚¬ì´ì¦ˆ
buyer_daily_top	êµ¬ë§¤ìžê°€ í‰ì†Œ ìž…ëŠ” ìƒì˜ ì‚¬ì´ì¦ˆ
buyer_daily_bottom	êµ¬ë§¤ìžê°€ í‰ì†Œ ìž…ëŠ” í•˜ì˜ ì‚¬ì´ì¦ˆ
buyer_realbuy_size	êµ¬ë§¤ìžê°€ ì‹¤ì œ êµ¬ë§¤í•œ ì‹ ë°œ ì‚¬ì´ì¦ˆ
buyer_color_fit_yn	êµ¬ë§¤ìžê°€ ì„ íƒí•œ ìƒ‰ìƒì´ ë§žì•˜ëŠ”ì§€ ì—¬ë¶€ (ì˜ˆ: Y/N)
buyer_ball_yn	êµ¬ë§¤ìžê°€ ë°œë³¼ì— ëŒ€í•´ ë¦¬ë·°í–ˆëŠ”ì§€ ì—¬ë¶€
buyer_instep_yn	êµ¬ë§¤ìžê°€ ë°œë“± ë†’ì´ì— ëŒ€í•´ ë¦¬ë·°í–ˆëŠ”ì§€ ì—¬ë¶€


ðŸ“Œ 4. ì œí’ˆ ì°©ìš©ê°(í•) ê´€ë ¨ ì»¬ëŸ¼
ë°œë³¼ (ball), ë°œë“± ë†’ì´ (instep), ìƒ‰ìƒ (color), ê¸¸ì´ (length) ë“±..

ë°œë“±
----
stat_instep_very_low	ë°œë“±ì´ ë§¤ìš° ë‚®ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_instep_low	ë°œë“±ì´ ë‚®ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_instep_fit	ë°œë“±ì´ ì ë‹¹í•˜ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_instep_high	ë°œë“±ì´ ë†’ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_instep_very_high	ë°œë“±ì´ ë§¤ìš° ë†’ë‹¤ê³  í‰ê°€ëœ ìˆ˜
âœ” ë°œë³¼ ê´€ë ¨ ì»¬ëŸ¼

ë°œë³¼
---
stat_ball_very_narr	ë°œë³¼ì´ ë§¤ìš° ì¢ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_ball_narr	ë°œë³¼ì´ ì¢ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_ball_fit	ë°œë³¼ì´ ì ë‹¹í•˜ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_ball_wide	ë°œë³¼ì´ ë„“ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_ball_very_wide	ë°œë³¼ì´ ë§¤ìš° ë„“ë‹¤ê³  í‰ê°€ëœ ìˆ˜
âœ” ìƒ‰ìƒ ê´€ë ¨ ì»¬ëŸ¼

ìƒ‰ìƒ
---
stat_color_very_bright	ìƒ‰ìƒì´ ë§¤ìš° ë°ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_color_little_bright	ìƒ‰ìƒì´ ì¡°ê¸ˆ ë°ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_color_fit	ìƒ‰ìƒì´ ì ë‹¹í•˜ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_color_little_dark	ìƒ‰ìƒì´ ì¡°ê¸ˆ ì–´ë‘¡ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_color_very_dark	ìƒ‰ìƒì´ ë§¤ìš° ì–´ë‘¡ë‹¤ê³  í‰ê°€ëœ ìˆ˜
âœ” ê¸¸ì´ ê´€ë ¨ ì»¬ëŸ¼

ê¸¸ì´
---
stat_length_10_short	ê¸¸ì´ê°€ 10% ì§§ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_length_5_short	ê¸¸ì´ê°€ 5% ì§§ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_length_fit	ê¸¸ì´ê°€ ì ë‹¹í•˜ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_length_5_long	ê¸¸ì´ê°€ 5% ê¸¸ë‹¤ê³  í‰ê°€ëœ ìˆ˜
stat_length_10_long	ê¸¸ì´ê°€ 10% ê¸¸ë‹¤ê³  í‰ê°€ëœ ìˆ˜
```
# 2. ë°ì´í„° ì „ì²˜ë¦¬
## 0. Col : reivew_contents  ì „ì²˜ë¦¬ ìž‘ì—…
### 0-ï¼‘. review_contents : (NaN, íŠ¹ìˆ˜ë¬¸ìžë¡œë§Œ ì´ë£¨ì–´ì ¸ ìžˆëŠ” ê²½ìš° ì œê±°)

* ë¦¬ë·° ë°ì´í„°ì—ì„œ ë¶ˆí•„ìš”í•œ ë°ì´í„°ë¥¼ ì œê±°.
# ë¦¬ë·° í…ìŠ¤íŠ¸ì— NaNê°’ì´ ì¡´ìž¬í•˜ëŠ” ê²½ìš°. (shoes_df[shoes_df['review_contents'].isna()] ë¡œ í™•ì¸.)
print('NaNê°’ì„ ì‚­ì œí•˜ê¸° ì „', shoes_df.shape)
nan_contents = shoes_df.index[shoes_df['review_contents'].isna()] #df íƒ€ìž….
shoes_df = shoes_df.drop(nan_contents)
print('NaNê°’ì„ ì‚­ì œí•œ ì´í›„', shoes_df.shape)
# ë¦¬ë·° í…ìŠ¤íŠ¸ê°€ íŠ¹ìˆ˜ë¬¸ìžë¡œë§Œ ì´ë£¨ì–´ì ¸ ìžˆëŠ” ê²½ìš°.
special_char_rows = shoes_df[shoes_df['review_contents'].str.match(r'^[\W_]+$', na=False)]

# í•¨ê»˜ ì‚´íŽ´ë³´ëŠ” ì»¬ëŸ¼ : grade
special_char_rows.loc[special_char_rows.index,['grade', 'review_contents']]
print('íŠ¹ìˆ˜ë¬¸ìžë¡œ ì´ë£¨ì–´ì§„ ë¦¬ë·°ë¥¼ ì‚­ì œí•˜ê¸° ì „',shoes_df.shape)
shoes_df = shoes_df.drop(special_char_rows.index)
print('íŠ¹ìˆ˜ë¬¸ìžë¡œ ì´ë£¨ì–´ì§„ ë¦¬ë·°ë¥¼ ì‚­ì œí•œ ì´í›„',shoes_df.shape)
### 0-ï¼’. review_contents : ìˆ«ìžë¡œë§Œ ì´ë£¨ì–´ì ¸ ìžˆëŠ” ê²½ìš°

* ë¦¬ë·° ë°ì´í„°ì—ì„œ ë¶ˆí•„ìš”í•œ ë°ì´í„°ë¥¼ ì œê±°.
# ë¦¬ë·° ë°ì´í„°ê°€ ìˆ«ìžë¡œë§Œ ì´ë£¨ì—¬ì ¸ ìžˆëŠ” ê²½ìš°
num_contents = shoes_df[shoes_df['review_contents'].str.match(r'^\d+$')]

# êµ¬ë§¤ ì ìˆ˜ì™€ í•¨ê»˜ ì‚´íŽ´ë³´ê¸°(ë¦¬ë·° ë°ì´í„°)
num_contents_rows = num_contents.loc[num_contents.index,['grade', 'review_contents']]
num_contents_rows
# ìˆ«ìž ë¦¬ë·° ë°ì´í„° ì‚­ì œ
print('ìˆ«ìžë¡œë§Œ ì´ë£¨ì–´ì§„ ë¦¬ë·° í…ìŠ¤íŠ¸ ì‚­ì œ ì „', shoes_df.shape)
shoes_df = shoes_df.drop(num_contents_rows.index)
print('ìˆ«ìžë¡œë§Œ ì´ë£¨ì–´ì§„ ë¦¬ë·° í…ìŠ¤íŠ¸ ì‚­ì œ ì´í›„', shoes_df.shape)
### 0-3. review_contents :í•œ ê°œ ì´ìƒì˜ ë¬¸ìž(ìžìŒ, ëª¨ìŒ, ì•ŒíŒŒë²³ ë“±)ìœ¼ë¡œë§Œ ë°˜ë³µë˜ëŠ” ê²½ìš°.

* ë¦¬ë·° ë°ì´í„°ì—ì„œ ë¶ˆí•„ìš”í•œ ë°ì´í„°ë¥¼ ì œê±°.
# í•œ ê°œ ì´ìƒì˜ ë¬¸ìž(ìžìŒ, ëª¨ìŒ, ì•ŒíŒŒë²³ ë“±)ë§Œ ë°˜ë³µë˜ëŠ” ê²½ìš°
repeated_chars = shoes_df[shoes_df['review_contents'].str.match(r'^(.+?)\1+$')]

# ì ìˆ˜ì™€ í•¨ê»˜ ì‚´íŽ´ë³´ê¸°.
repeated_chars_rows = repeated_chars.loc[repeated_chars.index,['grade', 'review_contents']]
repeated_chars_rows
import re
# ë°˜ë³µë˜ëŠ” ë¬¸ìž¥ì„ ì°¾ì•„ í•œë²ˆë§Œ ë‚¨ê¸°ê³  ì œê±°í•˜ê¸°.
def remove_repeated_phases(review_contents):
    """
    ë°˜ë³µë˜ëŠ” ë¬¸ìž¥(ë‹¨ì–´)ì„ ì°¾ì•„ì„œ ì²«ë²ˆì§¸ ë¬¸ìž¥(ë‹¨ì–´)ë¥¼ ì œì™¸í•˜ê³ 
    ëª¨ë‘ ì œê±°í•˜ëŠ” í•¨ìˆ˜ìž…ë‹ˆë‹¤.
    """

    # ì°¾ê³ ìž í•˜ëŠ” íŒ¨í„´
    regax_pattern =  r'^(.+?)\1+$'


    # colì˜ ë°ì´í„° ê°’ì´ íŒ¨í„´ê³¼ ì™„ì „ížˆ ì¼ì¹˜í•˜ëŠ”ê°€ì— ëŒ€í•œ ì—¬ë¶€
    match_review_texts = re.fullmatch(regax_pattern, review_contents)

    # 1ê°œì˜ ê·¸ë£¹ë§Œ ë‚¨ê²¨ë†“ê¸° (ë°˜ë³µë˜ëŠ” ë¶€ë¶„ ëª¨ë‘ ì œê±°)
    return match_review_texts.group(1) if match_review_texts else review_contents
# ì¶”ë ¤ë†“ì€ dfì— ì ìš©.
repeated_chars.loc[:,'review_contents'] = repeated_chars['review_contents'].apply(remove_repeated_phases)

# ìˆ˜ì •í•œ ë¶€ë¶„ì„ ì›ëž˜ dfì— ì–¹ê¸°.
shoes_df.update(repeated_chars)
### 0-ï¼”. review_contents :ì•ŒíŒŒë²³ìœ¼ë¡œë§Œ ì´ë£¨ì–´ì§„ ê²½ìš°

* ë¦¬ë·° ë°ì´í„°ì—ì„œ ë¶ˆí•„ìš”í•œ ë°ì´í„°ë¥¼ ì œê±°.
# ì•ŒíŒŒë²³ìœ¼ë¡œë§Œ ì´ë£¨ì–´ì§„ ê²½ìš°
only_alpha_chars = shoes_df[shoes_df['review_contents'].str.match(r'^[a-zA-Z]+$')]
only_alpha_chars[['grade','review_contents']]
print('ì•ŒíŒŒë²³ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ë¦¬ë·° í…ìŠ¤íŠ¸ ì‚­ì œ ì „', shoes_df.shape)
shoes_df = shoes_df.drop(only_alpha_chars.index)
print('ì•ŒíŒŒë²³ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ë¦¬ë·° í…ìŠ¤íŠ¸ ì‚­ì œ ì´í›„', shoes_df.shape)
## 1. ì‹ ë°œëª… í’ˆëª©í™”

* ë¸Œëžœë“œë³„ ì œí’ˆëª… í’ˆëª©í™”
    * ë¸Œëžœë“œëª… í†µì¼ ì´í›„ ì§„í–‰.
shoes_df['brand_name'].unique()
shoes_df['product_name'].unique()
#### â€» ì°¸ê³ . ë°˜ìŠ¤ ë°ì´í„°
    ```
    * DX : ë³µê°ë¼ì¸, ì•„ì›ƒì†”ì— ì½”íŒ…ì´ ë˜ì–´ ìžˆê³  ë°‘ì°½ì´ í´ëž˜ì‹(ê¸°ë³¸ ëª¨ë¸)ë³´ë‹¤ í‘¹ì‹ 
    * ë³¼íŠ¸ : ë³¼íŠ¸ ë¼ì¸ì€ ë°˜ìŠ¤ì—ì„œ ìµœìƒìœ„ ë¼ì¸
    * ë¼ì´íŠ¸ : ì–´ì„¼í‹± ë³´ë‹¤ ê°€ë²¼ì›€
    * ë¡œí”„ë¡œ : ì–´ì„¼í‹±ê³¼ ë‹¤ë¥´ê²Œ í­ì‹± í…Œì´í”„ ì—†ì´ ë³´ë‹¤ ë¯¸ë‹ˆë©€í•˜ê²Œ ë””ìžì¸í–ˆë‹¤.  ì–´ì„¼í‹± ë¡œìš°í”„ë¡œëŠ” ì–´ì„¼í‹±ì— ë¹„í•´ ë¯¸ë“œì†” ë†’ì´ê°€ ì•½ 1cm ì •ë„ ë‚®ì•„ì¡Œë‹¤.
    * vr3 : ì¹œí™˜ê²½ ì†Œìž¬.
    * í”Œëž«í¼ : ë””ìžì¸ ë‹¤ë¦„, ìœ¡ì•ˆìœ¼ë¡œ ëª»ì•Œì•„ë´ì„œ ì²˜ìŒì— í•©ì³¤ìŒ êµ½ë†’ì´ë„ ë‹¤ë¦„
    * ì»´í”¼ì¿ ì‹œ : ì‚¬ì´ì¦ˆ ìž‘ìŒ
    * SF: SFëŠ” ì„œí•‘ ìŠ¤íƒ€ì¼ì„ ê°•ì¡°í•˜ë©° SFëŠ” ì§€ì† ê°€ëŠ¥í•œ ìž¬ë£Œë¥¼ ì‚¬ìš©.
    * í¬ë¦¬í¼ : ë‘êº¼ìš´ ë°‘ì°½, ê·¸ëž€ì§€ ìŠ¤íƒ€ì¼ ê°•ì¡°.
    * í˜¸ë²„ : ë” ë‘êº¼ìš´ ë°‘ì°½ì„ ê°€ì§€ê³  ìžˆì–´ ìŠ¤íƒ€ì¼ê³¼ íŽ¸ì•ˆí•¨ì„ ë™ì‹œì— ì œê³µ, 4cmì˜ í”Œëž«(PLAT) ë°‘ì°½ì´ íŠ¹ì§•,ê²½ëŸ‰ ì†Œìž¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì°©ìš©ê°ì´ ìš°ìˆ˜í•˜ë©°, ë°œì— ë” ìž˜ ë§žë„ë¡ ì„¤ê³„
    * ì²´ì»¤ë³´ë“œ : ì±„ì»¤ë³´ë“œ íŒ¨í„´ì´ íŠ¹ì§•ì¸ ëª¨ë¸.
    * ì—˜ë Œ : ìŠ¬ë¦½ì˜¨ë³´ë‹¤ ë” íŒ¨ë”©ì´ ë‘ê»ê³ , ë°œëª©ì„ ê°ì‹¸ëŠ” ë””ìžì¸ìœ¼ë¡œ íŽ¸ì•ˆí•¨ì„ ê°•ì¡°, ì†Œìž¬: Duracapâ„¢ ê¸°ìˆ ì´ ì ìš©ëœ ë‚´êµ¬ì„± ìžˆëŠ” ì†Œìž¬ë¡œ ì œìž‘ë˜ì–´, ë°œê°€ë½ ë¶€ë¶„ì˜ ë‚´êµ¬ì„±ì´ ê°•í™”ë¨, ìž¥ì‹œê°„ ì„œ ìžˆê±°ë‚˜ ê±·ëŠ” ë° ì í•©í•œ ë””ìžì¸ìœ¼ë¡œ, íŽ¸ì•ˆí•¨ì„ ì¤‘ì‹œí•˜ëŠ” ì‚¬ìš©ìžì—ê²Œ ì¶”ì²œë¨..
    *  138  : ë°œëª©ì„ ë” ìž˜ ì§€ì§€í•˜ëŠ” ë””ìžì¸ìœ¼ë¡œ, í´ëž˜ì‹ ìŠ¬ë¦½ì˜¨ë³´ë‹¤ ë” ë†’ì€ í˜•íƒœ
    ```
### 2-1. ë°˜ìŠ¤ í’ˆëª©í™” 
vans_df = shoes_df[shoes_df['brand_name'] == 'VANS']
vans_df.shape
vans_df['product_name'].value_counts()
#### (1) ì»¬ëŸ¬ ë ì–´ë¦¬ ìž‘ì—…
color_theory = vans_df[vans_df['product_name'].str.contains('ì»¬ëŸ¬ ë ì–´ë¦¬')]
print('"ì»¬ëŸ¬ ë ì–´ë¦¬"ê°€ í¬í•¨ëœ í’ˆëª©ëª…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:')

for name in color_theory['product_name'].unique():
    print(f'\n {name}')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'í´ëž˜ì‹ ìŠ¬ë¦½-ì˜¨ - ì»¬ëŸ¬ ë ì–´ë¦¬ ì²´ì»¤ë³´ë“œ ì•„íŠ¸ëª¨ìŠ¤í”¼ì–´', 'í´ëž˜ì‹ ìŠ¬ë¦½ì˜¨ ì»¬ëŸ¬ ë ì–´ë¦¬')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ì˜¬ë“œ ìŠ¤ì¿¨ - ì»¬ëŸ¬ ë ì–´ë¦¬ ë”ìŠ¤í‹° ë¸”ë£¨', 'ì˜¬ë“œìŠ¤ì¿¨ ì»¬ëŸ¬ ë ì–´ë¦¬')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ì–´ì„¼í‹± - ì»¬ëŸ¬ ë ì–´ë¦¬ ì•„ì´ìŠ¤ë²„ê·¸ ê·¸ë¦°', 'ì–´ì„¼í‹± ì»¬ëŸ¬ ë ì–´ë¦¬')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ìŠ¤ì¼€ì´íŠ¸-í•˜ì´ - ì»¬ëŸ¬ ë ì–´ë¦¬ í”„ë Œì¹˜ ì˜¤í¬', 'ìŠ¤ì¼€ì´íŠ¸ í•˜ì´ ì»¬ëŸ¬ ë ì–´ë¦¬')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'í´ëž˜ì‹ ìŠ¬ë¦½-ì˜¨ ì»¬ëŸ¬ ë ì–´ë¦¬ ë¹„ì»¨ ë¸”ë£¨', 'í´ëž˜ì‹ ìŠ¬ë¦½ì˜¨ ì»¬ëŸ¬ ë ì–´ë¦¬')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ì–´ì„¼í‹± -  ì»¬ëŸ¬ ë ì–´ë¦¬ ë”ìŠ¤í‹° ë¸”ë£¨', 'ì–´ì„¼í‹± ì»¬ëŸ¬ ë ì–´ë¦¬')

color_theory = vans_df[vans_df['product_name'].str.contains('ì»¬ëŸ¬ ë ì–´ë¦¬')]
print('ðŸ“ "ì»¬ëŸ¬ ë ì–´ë¦¬"ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í’ˆëª©í™” í•œ ê²°ê³¼:')

for name in color_theory['product_name'].unique():
    print(f'\n {name}')
#### (2) ë®¬ ìž‘ì—…
muul= vans_df[vans_df['product_name'].str.contains('ë®¬')]
print('"ë®¬"ì´ í¬í•¨ëœ í’ˆëª©ëª…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:')

for name in muul['product_name'].unique():
    print(f'\n {name}')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'í´ëž˜ì‹ ìŠ¬ë¦½-ì˜¨ ë®¬ - ì²´ì»¤ë³´ë“œ ë¸”ëž™/í™”ì´íŠ¸',  'í´ëž˜ì‹ ìŠ¬ë¦½ì˜¨ ë®¬ ì»¬ëŸ¬ ë ì–´ë¦¬ ì²´ì»¤ë³´ë“œ')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ìŠ¬ë¦½ ì˜¨ ë®¬ í˜¸ë²„ - ë¸”ëž™/í™”ì´íŠ¸', 'ìŠ¬ë¦½ì˜¨ ë®¬ í˜¸ë²„')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ì˜¬ë“œ ìŠ¤ì¿¨ ë®¬ - ë¸”ëž™/íŠ¸ë£¨ í™”ì´íŠ¸', 'ì˜¬ë“œìŠ¤ì¿¨ ë®¬')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ì–´ì„¼í‹± ë®¬ - ë¸”ëž™/íŠ¸ë£¨ í™”ì´íŠ¸', 'ì–´ì„¼í‹± ë®¬')


muul= vans_df[vans_df['product_name'].str.contains('ë®¬')]
print('ðŸ“ "ë®¬"ì„ ê¸°ì¤€ìœ¼ë¡œ í’ˆëª©í™” í•œ ê²°ê³¼:')

for name in muul['product_name'].unique():
    print(f'\n {name}')
#### (ï¼“) ì²´ì»¤ë³´ë“œ ìž‘ì—….
checker_board = vans_df[vans_df['product_name'].str.contains('ì²´ì»¤ë³´ë“œ')]
checker_board['product_name'].unique()


print('"ì²´ì»¤ë³´ë“œ"ê°€ í¬í•¨ëœ í’ˆëª©ëª…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:')

for name in checker_board['product_name'].unique():
    print(f'\n {name}')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ì˜¬ë“œ ìŠ¤ì¿¨ - ë“œë ˆìŠ¤ ë¸”ë£¨ ì²´ì»¤ë³´ë“œ', 'ì˜¬ë“œìŠ¤ì¿¨ ì²´ì»¤ë³´ë“œ')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ì–´ì„¼í‹± - ì²´ì»¤ë³´ë“œ ë¸”ëž™/í™”ì´íŠ¸', 'ì–´ì„¼í‹± ì²´ì»¤ë³´ë“œ')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ìŠ¬ë¦½-ì˜¨ VR3 - ì²´ì»¤ë³´ë“œ ë¸”ëž™/ë§ˆì‰¬ë©œë¡œìš°', 'ìŠ¬ë¦½ì˜¨ VR3 ì²´ì»¤ë³´ë“œ')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ì–´ì„¼í‹± - ì²´ì»¤ë³´ë“œ ë¸Œë¼ìš´', 'ì–´ì„¼í‹± ì²´ì»¤ë³´ë“œ')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ì˜¬ë“œ ìŠ¤ì¿¨ í”Œëž«í¼ - ì²´ì»¤ë³´ë“œ ë¸”ëž™/íŠ¸ë£¨ í™”ì´íŠ¸', 'ì˜¬ë“œìŠ¤ì¿¨ í”Œëž«í¼ ì²´ì»¤ë³´ë“œ')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ì–´ì„¼í‹± - ì²´ì»¤ë³´ë“œ ë¬¸ ë½', 'ì–´ì„¼í‹± ì²´ì»¤ë³´ë“œ')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ì–´ì„¼í‹± - ì²´ì»¤ë³´ë“œ ë¸”ë£¨/í™”ì´íŠ¸', 'ì–´ì„¼í‹± ì²´ì»¤ë³´ë“œ')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ìŠ¬ë¦½-ì˜¨ VR3 SF - ì²´ì»¤ë³´ë“œ ë¸”ëž™/ë§ˆì‰¬ë©œë¡œìš°', 'ìŠ¬ë¦½ì˜¨ VR3 SF ì²´ì»¤ë³´ë“œ')



checker_board= vans_df[vans_df['product_name'].str.contains('ì²´ì»¤ë³´ë“œ')]
print('ðŸ“ "ì²´ì»¤ë³´ë“œ"ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í’ˆëª©í™” í•œ ê²°ê³¼:')

for name in checker_board['product_name'].unique():
    print(f'\n {name}')
#### (4) ë°œë ˆë¦¬ë‚˜ ìž‘ì—….
ballet = vans_df[vans_df['product_name'].str.contains('ë°œë ˆ')]
ballet['product_name'].unique()
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ë©”ë¦¬ ì œì¸ - ë°œë ˆë¦¬ë‚˜ ë¸”ëž™', 'ë©”ë¦¬ì œì¸ ë°œë ˆë¦¬ë‚˜')
#### (5) ì˜¨ ìž‘ì—….
on = vans_df[vans_df['product_name'].str.contains('ì˜¨')]

print('"ì˜¨"ì´ í¬í•¨ëœ í’ˆëª©ëª…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:')

for name in on['product_name'].unique():
    print(f'\n {name}')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ìŠ¬ë¦½ ì˜¨ ì—˜ë ™ - ë„¤ì´ë¹„/í™”ì´íŠ¸', 'ìŠ¬ë¦½ì˜¨ ì—˜ë ™')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'í´ëž˜ì‹ ìŠ¬ë¦½-ì˜¨ - ë¸”ëž™ ì•¤ í™”ì´íŠ¸ ì²´ì»¤/í™”ì´íŠ¸', 'í´ëž˜ì‹ ìŠ¬ë¦½ì˜¨')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ìŠ¬ë¦½ ì˜¨ ì—˜ë ™ - S.ë² ì´ì§€/í™”ì´íŠ¸', 'ìŠ¬ë¦½ì˜¨ ì—˜ë ™')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'ìŠ¬ë¦½ ì˜¨ í˜¸ë²„ - ë¸”ëž™/í™”ì´íŠ¸/ì²´í¬', 'ìŠ¬ë¦½ì˜¨ í˜¸ë²„')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'í´ëž˜ì‹ ìŠ¬ë¦½-ì˜¨ - íŠ¸ë£¨ í™”ì´íŠ¸', 'í´ëž˜ì‹ ìŠ¬ë¦½ì˜¨')
vans_df.loc[:, 'product_name'] = vans_df['product_name'].str.replace(r'í´ëž˜ì‹ ìŠ¬ë¦½-ì˜¨ - ë¸”ëž™', 'í´ëž˜ì‹ ìŠ¬ë¦½ì˜¨')


on = vans_df[vans_df['product_name'].str.contains('ì˜¨')]
print('ðŸ“ "ì˜¨"ì„ ê¸°ì¤€ìœ¼ë¡œ í’ˆëª©í™” í•œ ê²°ê³¼:')

for name in on['product_name'].unique():
    print(f'\n {name}')
## 2. ì»¬ëŸ¼ : ë¸Œëžœë“œëª… & grade í†µì¼
# ë¸Œëžœë“œ ì´ë¦„ í†µì¼.
shoes_df.loc[shoes_df['brand_name'] == 'adidas', 'brand_name'] = 'ADIDAS'

# grade ë“±ê¸‰ í†µì¼.
shoes_df.loc[shoes_df['grade'] == 'ì•„ì£¼ ì¢‹ì•„ìš”', 'grade'] = '5.0'
shoes_df.loc[shoes_df['grade'] == 'ë§˜ì— ë“¤ì–´ìš”', 'grade'] = '4.0'
shoes_df.loc[shoes_df['grade'] == 'ë³´í†µì´ì—ìš”', 'grade'] = '3.0'
shoes_df.loc[shoes_df['grade'] == 'ê·¸ëƒ¥ ê·¸ëž˜ìš”', 'grade'] = '2.0'
shoes_df.loc[shoes_df['grade'] == 'ë³„ë¡œì˜ˆìš”', 'grade'] = '1.0'
## 3. ì¤‘ìš” ì»¬ëŸ¼ Nanê°’ í™•ì¸
shoes_df.info()
### 3-1. grade ì»¬ëŸ¼
# grade typeì´ objectê³¼ floatê°€ ì„žì—¬ìžˆìŒ
shoes_df['grade'].value_counts()
shoes_df['grade'] = shoes_df['grade'].astype(str).str.strip().astype(float)
# gradeê°’ì„ ì±„ìš°ê¸° ìœ„í•´ product_idë³„ gradeê°’ì˜ í‰ê· ê°’ìœ¼ë¡œ ì±„ìš°ë ¤ê³  í•œë‹¤.

# product_idë³„ í‰ê·  ê°’ì„ ë°˜ì˜¬ë¦¼í•¨.
product_grade_mean_rounded = shoes_df.groupby('product_id')['grade'].mean().round(0)
# nanê°’ì„ ê°€ì§€ê³  ìžˆëŠ” product_idì¼ ê²½ìš° product_grade_mean_roundedì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´
for idx in shoes_df.index:
    if pd.isna(shoes_df.loc[idx, 'grade']) :
        product_id = shoes_df.loc[idx, 'product_id']
        if product_id in product_grade_mean_rounded :
            shoes_df.loc[idx, 'grade'] = product_grade_mean_rounded[product_id]
### 3-2. useful ì»¬ëŸ¼
# 0ìœ¼ë¡œ ì±„ì›Œë„£ê¸°
shoes_df['useful_count'] = shoes_df['useful_count'].fillna(0.0)
### 3-3. product color ì»¬ëŸ¼
    - ë„ˆë¬´ ë§Žì€ ì¢…ë¥˜ì˜ ì»¬ëŸ¬ ìˆ˜ê°€ ì¡´ìž¬.
    - ì¼ì • ì¢…ë¥˜ì˜ ì»¬ëŸ¼ ìˆ˜ë¡œ ì •ì œ
    - ë‚˜ë¨¸ì§€ëŠ” Otherë¡œ ë°˜í™˜
### 3-4. product gender ì»¬ëŸ¼
    - ABC Martì™€ ShoesMarker ì‚¬ì´íŠ¸ì—ì„œëŠ” ì„±ë³„ì´ ì—†ìŒ.
    - ì„±ë³„ ì»¬ëŸ¼ì€ ì¤‘ìš”í•œ ì»¬ëŸ¼ìœ¼ë¡œ ìƒê°, ê° ì‚¬ì´íŠ¸ì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ë° ìž…ë ¥ 
# 3. ì „ì²˜ë¦¬ ì™„ë£Œëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° 
shoes_df = pd.read_csv("cleaned_shoes_data_1st.csv")
# # 1. product_id ê¸°ì¤€ìœ¼ë¡œ ëŒ€í‘œ product_name í•˜ë‚˜ë§Œ ì¶”ì¶œ (ì¤‘ë³µ ì œê±°)
# vans_name_map = vans_df.drop_duplicates(subset='product_id').set_index('product_id')['product_name']

# # 2. shoes_dfì˜ VANS ì œí’ˆë§Œ ë§ˆìŠ¤í¬ë§
# vans_mask = shoes_df['brand_name'] == 'VANS'

# # 3. product_id ê¸°ì¤€ìœ¼ë¡œ ì •ì œëœ product_name ë®ì–´ì“°ê¸°
# shoes_df.loc[vans_mask, 'product_name'] = shoes_df.loc[vans_mask, 'product_id'].map(vans_name_map)
shoes_df['product_color'] = shoes_df['color']
shoes_df['product_gender'] = shoes_df['edited_product_gender']
# 4. ì‹œê°í™”
import seaborn as sns
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import matplotlib.font_manager as fm
# í•œê¸€ í°íŠ¸ ì„¤ì • (ì˜ˆ: ë‚˜ëˆ”ê³ ë”•)
plt.rc('font', family='NanumGothic')
## 4-1. í‰ì  ë¶„í¬
sns.histplot(shoes_df['grade'], bins = 20)
plt.title('í‰ì  ë¶„í¬')
plt.xlabel('í‰ì ')
plt.ylabel('ë¦¬ë·° ìˆ˜')
plt.show()
- ì „ë°˜ì ì¸ ì‚¬ìš©ìž ë§Œì¡±ë„ëŠ” 5ì ì´ ì œì¼ ë†’ì€ ê²ƒìœ¼ë¡œ í™•ì¸
## 4-2. ë¸Œëžœë“œë³„ í‰ê·  í‰ì 
brand_avg = shoes_df.groupby('brand_name')['grade'].mean().sort_values(ascending = False)
sns.barplot(x = brand_avg.values, y = brand_avg.index)
plt.title('ë¸Œëžœë“œë³„ í‰ê·  í‰ì ')
plt.xlabel('í‰ê·  í‰ì ')
plt.ylabel('ë¸Œëžœë“œ')
plt.show()
- ëŒ€ë¶€ë¶„ì˜ í‰ì ì´ ë¹„ìŠ·, ë†’ê²Œ ë¶„í¬
### 1) ë¸Œëžœë“œë³„ë¡œ í‰ì ì˜ ë¶„í¬ í™•ì¸
brands = shoes_df['brand_name'].unique()

n_cols = 4
n_rows = (len(brands) + n_cols - 1) // n_cols
fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))

# ì§ì ‘ Bins ì„¤ì •: í‰ì  0~5ë¥¼ 0.5 ë‹¨ìœ„ë¡œ ëŠê¸°
bins = [0, 0.5, 1.5, 2.5, 3.5, 4.5, 5]

for idx, brand in enumerate(brands):
    ax = axes[idx // n_cols, idx % n_cols]
    brand_data = shoes_df[shoes_df['brand_name'] == brand]
    ax.hist(brand_data['grade'], bins=bins, edgecolor='black')
    ax.set_title(brand)
    ax.set_xlim(0, 5)
    ax.set_xticks([0, 1, 2, 3, 4, 5])
    ax.set_xlabel('í‰ì ')
    ax.set_ylabel('ë¦¬ë·° ìˆ˜')

# ë¹ˆ ê³µê°„ ì—†ì• ê¸°
for idx in range(len(brands), n_rows * n_cols):
    fig.delaxes(axes[idx // n_cols, idx % n_cols])

plt.suptitle('ë¸Œëžœë“œë³„ í‰ì  ë¶„í¬ (0~5)', fontsize=20)
plt.tight_layout(rect=[0, 0, 1, 0.97])
plt.show()
- ê° ë¸Œëžœë“œë³„ í‰ì  ë¶„í¬ëŠ” 5ì ì´ ì œì¼ ë§ŽìŒ, ê·¸ ë‹¤ìŒ 4ì  3ì  ìˆœ
    - VANSì™€ NIKE, NEWBALANCEëŠ” 1ì ì´ ë‹¤ë¥¸ ë¸Œëžœë“œì— ë¹„í•´ ë” ë¶„í¬í•¨.
- ADIDAS > VANS > CONVERS ìˆœìœ¼ë¡œ ë¦¬ë·° ìˆ˜ ë¶„í¬
shoes_df[shoes_df['grade'] == 1].groupby('brand_name')['grade'].mean()
### 2) ë¸Œëžœë“œë³„ 1ì ëŒ€ ë¹„ìœ¨
one_grade_ratio = shoes_df.groupby('brand_name').apply(lambda x: (x['grade'] == 1).mean()).sort_values(ascending=False)

plt.figure(figsize=(10,6))
sns.barplot(x=one_grade_ratio.values, y=one_grade_ratio.index)
plt.title('ë¸Œëžœë“œë³„ 1ì  ë¦¬ë·° ë¹„ìœ¨')
plt.xlabel('1ì  ë¹„ìœ¨')
plt.ylabel('ë¸Œëžœë“œ')
# plt.xlim(0,1)
plt.show()

- ë¸Œëžœë“œë³„ 1ì  ëŒ€ ë¹„ìœ¨ì€ ë‚˜ì´í‚¤ê°€ ì œì¼ ë†’ìŒ
import matplotlib.pyplot as plt
import seaborn as sns

# ë¶„ì„í•  ë¸Œëžœë“œ ë¦¬ìŠ¤íŠ¸
brands = shoes_df['brand_name'].unique()

# ê·¸ëž˜í”„ í¬ê¸° ì„¤ì •
plt.figure(figsize=(20, 30))

# ë¸Œëžœë“œë³„ë¡œ ë°˜ë³µ
for idx, brand in enumerate(brands, 1):
    plt.subplot(4, 2, idx)  # 4í–‰ 2ì—´ subplot

    # í•´ë‹¹ ë¸Œëžœë“œì—ì„œ gradeê°€ 1 ë˜ëŠ” 2ì¸ ë°ì´í„°ë§Œ í•„í„°ë§
    brand_df = shoes_df[(shoes_df['brand_name'] == brand) & (shoes_df['grade'].isin([1, 2]))]
    
    # ìƒí’ˆë³„ë¡œ 1ì +2ì  ë¦¬ë·° ê°œìˆ˜ ì¹´ìš´íŠ¸
    product_counts = brand_df['product_name'].value_counts().head(10)  # ìƒìœ„ 10ê°œ
    
    # barplot ê·¸ë¦¬ê¸°
    sns.barplot(x=product_counts.values, y=product_counts.index, palette='Reds_r')
    plt.title(f'{brand} - 1ì +2ì  ë¦¬ë·° ë§Žì€ ìƒí’ˆ Top10')
    plt.xlabel('1ì +2ì  ë¦¬ë·° ìˆ˜')
    plt.ylabel('ìƒí’ˆëª…')

plt.tight_layout()
plt.show()
import matplotlib.pyplot as plt
import seaborn as sns

# ë¶„ì„í•  ë¸Œëžœë“œ ë¦¬ìŠ¤íŠ¸
brands = shoes_df['brand_name'].unique()

# ê·¸ëž˜í”„ í¬ê¸° ì„¤ì •
plt.figure(figsize=(20, 30))

# ë¸Œëžœë“œë³„ë¡œ ë°˜ë³µ
for idx, brand in enumerate(brands, 1):
    plt.subplot(4, 2, idx)  # 4í–‰ 2ì—´ subplot

    # í•´ë‹¹ ë¸Œëžœë“œì—ì„œ gradeê°€ 1 ë˜ëŠ” 2ì¸ ë°ì´í„°ë§Œ í•„í„°ë§
    brand_df = shoes_df[(shoes_df['brand_name'] == brand) & (shoes_df['grade'].isin([4, 5]))]
    
    # ìƒí’ˆë³„ë¡œ 1ì +2ì  ë¦¬ë·° ê°œìˆ˜ ì¹´ìš´íŠ¸
    product_counts = brand_df['product_name'].value_counts().head(10)  # ìƒìœ„ 10ê°œ
    
    # barplot ê·¸ë¦¬ê¸°
    sns.barplot(x=product_counts.values, y=product_counts.index, palette='Blues')
    plt.title(f'{brand} - 4ì +5ì  ë¦¬ë·° ë§Žì€ ìƒí’ˆ Top10')
    plt.xlabel('4ì +5ì  ë¦¬ë·° ìˆ˜')
    plt.ylabel('ìƒí’ˆëª…')

plt.tight_layout()
plt.show()
## 4-3. ì œí’ˆë³„ ë¦¬ë·° ìˆ˜ Top 10
top_products = shoes_df['product_name'].value_counts().head(10)
sns.barplot(x=top_products.values, y=top_products.index)
plt.title('ì œí’ˆë³„ ë¦¬ë·° ìˆ˜ TOP 10')
plt.xlabel('ë¦¬ë·° ìˆ˜')
plt.ylabel('ì œí’ˆëª…')
plt.show()
## 4-4. ì»¬ëŸ¬ë³„ í‰ê·  í‰ì 
color_avg = shoes_df.groupby('product_color')['grade'].mean().sort_values(ascending=False).head(10)
sns.barplot(x=color_avg.values, y=color_avg.index)
plt.title('ì»¬ëŸ¬ë³„ í‰ê·  í‰ì ')
plt.xlabel('í‰ê·  í‰ì ')
plt.ylabel('ì œí’ˆ ìƒ‰ìƒ')
plt.show()
## 4-5. ê°€ê²© í‰ì  ì‚°ì ë„
scatter_df = shoes_df[['product_price', 'grade']]
scatter_df.info()
scatter_df['product_price'] = scatter_df['product_price'].str.replace(",", "")
scatter_df['product_price'] = scatter_df['product_price'].astype(int)
scatter_df.info()
sns.scatterplot(data = scatter_df, x = 'product_price', y = 'grade')
plt.xlabel('ê°€ê²©(ì›)')
plt.ylabel('í‰ì ')
plt.show()
## 4-6. ìœ ìš©í•œ ë¦¬ë·° ìˆ˜ ë¶„í¬
sns.histplot(shoes_df['useful_count'])
plt.show()
- 0~100 ì‚¬ì´ì— ì§‘ì¤‘í•˜ê³  ìžˆìŒ
## 4-7. ë°œë³¼ ë„“ìŒê³¼ í‰ì 
- ë°œë³¼ ì°©ìš©ê° í‰ê°€ê°€ í‰ì ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ 
sns.boxplot(data = shoes_df, x = 'stat_ball_wide', y = 'grade')
plt.show()
## 4-8. ë°œë“± ë†’ìŒê³¼ í‰ì 
sns.boxplot(x='stat_instep_high', y='grade', data=shoes_df)
plt.title('ë°œë“± ë†’ìŒ ìˆ˜ vs í‰ì ')
plt.xlabel('ë°œë“± ë†’ìŒ í‰ê°€ ìˆ˜')
plt.ylabel('í‰ì ')
plt.show()
## 4-9. ë¦¬ë·° í…ìŠ¤íŠ¸ ì›Œë“œí´ë¼ìš°ë“œ
from wordcloud import WordCloud

text = ' '.join(shoes_df['review_contents'].dropna().astype(str))
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('ë¦¬ë·° ì›Œë“œí´ë¼ìš°ë“œ')
plt.show()
# 5. ëª¨ë¸ë§
shoes_df.head()
## 5-1. TF-IDF + ì½”ì‚¬ì¸
: ë¬¸ì„œ ì§‘í•©ì—ì„œ íŠ¹ì • ë‹¨ì–´ê° ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ë¥¼ ìˆ˜ì¹˜ë¡œ ë‚˜íƒ€ë‚´ëŠ” ëŒ€í‘œì ì¸ í…ìŠ¤íŠ¸ ë²¡í„°í™” ë°©ë²•

- TF : íŠ¹ì • ë¬¸ì„œ ë‚´ì—ì„œ ë‹¨ì–´ê°€ ì–¼ë§ˆë‚˜ ìžì£¼ ë“±ìž¥í•˜ëŠ”ì§€
- IDF : í•´ë‹¹ ë‹¨ì–´ê°€ ì „ì²´ ë¬¸ì„œ ì¤‘ì—ì„œ ì–¼ë§ˆë‚˜ í¬ê·€í•œì§€

1. ì›ë¦¬
    1) ê° ì œí’ˆì˜ ë¦¬ë·°ë¥¼ ì œí’ˆë³„ë¡œ í•˜ë‚˜ë¡œ í•©ì³ í…ìŠ¤íŠ¸ë¡œ ë§Œë“¦
    2) TF-IDF ë°©ì‹ìœ¼ë¡œ ë°±í„°í™”í•œ ë’¤
    3) ì‚¬ìš©ìžì˜ ìž…ë ¥ ë˜ëŠ” íŠ¹ì • ì œí’ˆê³¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°
    4) ê°€ìž¥ ìœ ì‚¬í•œ ì œí’ˆì„ ì¶”ì²œí•˜ëŠ” ë°©ì‹ (ìœ ì‚¬ë„ê°€ ë†’ì€ ê²ƒ)
tf_idf_shoes_df = shoes_df.copy()
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from konlpy.tag import Okt
1. í˜•íƒœì†Œ 
- ì˜ë¯¸ë¥¼ ê°€ì§€ëŠ” ê°€ìž¥ ìž‘ì€ ë‹¨ìœ„

2. ë¶ˆìš©ì–´
- ë¶„ì„ì— ì˜ë¯¸ ì—‰ã…„ëŠ” ë‹¨ì–´
    ì˜ˆ) ì¡°ì‚¬ë‚˜ ì ‘ì†ì‚¬, ì˜ë¯¸ í¬ì„ì–´ ë“±
    - ë¶ˆìš©ì–´ë¥¼ ì œê±°í•˜ë©´ TF-IDFì— ì˜ë¯¸ ìžˆëŠ” ë‹¨ì–´ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬ 
# í˜•íƒœì†Œ ë¶„ì„ê¸° ë° ë¶ˆìš©ì–´ ë¶ˆëŸ¬ì˜¤ê¸°
okt = Okt()
with open('stopwords.txt', encoding='utf-8') as f:
    stopwords = set(line.strip() for line in f if line.strip())
# í˜•íƒœì†Œ ë¶„ì„ + ë¶ˆìš©ì–´ ì œê±° í•¨ìˆ˜

def clean_korean_text(text) :
    if pd.isnull(text):
        return ''
    tokens = okt.morphs(text, stem=True)
    clean_tokens = [t for t in tokens if t not in stopwords]
    return ' '.join(clean_tokens)
# ì œí’ˆë³„ ë¦¬ë·° í†µí•©
product_reviews = tf_idf_shoes_df.groupby('product_name')['review_contents'].apply(lambda x: ' '.join(x)).reset_index()
product_reviews['cleaned_review'] = product_reviews['review_contents'].apply(clean_korean_text)
product_reviews
from wordcloud import WordCloud

text = ' '.join(product_reviews['cleaned_review'].dropna().astype(str))
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('ë¦¬ë·° ì›Œë“œí´ë¼ìš°ë“œ')
plt.show()
# TF-IDF ë²¡í„°í™”
vectorizer = TfidfVectorizer(max_features=5000)
review_tfidf_matrix = vectorizer.fit_transform(product_reviews['cleaned_review'])
def recommend_with_filters(query, top_n=5, color_filter=None, brand_filter=None):
    query_clean = clean_korean_text(query)
    query_vec = vectorizer.transform([query_clean])
    similarity_scores = cosine_similarity(query_vec, review_tfidf_matrix).flatten()
    
    product_reviews['similarity'] = similarity_scores
    top_df = product_reviews.copy()
    
    # shoes_dfì—ì„œ ì¶”ê°€ ì •ë³´ merge
    top_df = pd.merge(top_df, shoes_df[['product_name', 'brand_name', 'grade', 'product_color']], on='product_name', how='left')
    
    # í•„í„° ì ìš©
    if color_filter:
        top_df = top_df[top_df['product_color'].str.contains(color_filter, na=False, case=False)]
    if brand_filter:
        top_df = top_df[top_df['brand_name'].str.contains(brand_filter, na=False, case=False)]
    
    # âœ… product_name ê¸°ì¤€ ì¤‘ë³µ ì œê±°
    top_df = top_df.sort_values(by='similarity', ascending=False)
    top_df = top_df.drop_duplicates(subset='product_name', keep='first')
    
    return top_df.head(top_n)
# 5. ì‚¬ìš©ìž ìž…ë ¥ ê¸°ë°˜ ì¶”ì²œ ì‹¤í–‰
if __name__ == "__main__":
    print("ì‹ ë°œ ë¦¬ë·° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œìž…ë‹ˆë‹¤.\n")
    
    query = input("1ï¸ì–´ë–¤ ì‹ ë°œì„ ì°¾ê³  ê³„ì‹ ê°€ìš”? (ì˜ˆ: í­ì‹ í•˜ê³  ë°œë³¼ì´ ë„“ì€ ì‹ ë°œ): ")
    brand = input("2ï¸ì„ í˜¸ ë¸Œëžœë“œê°€ ìžˆìœ¼ì‹ ê°€ìš”? (ì˜ˆ: VANS, ì—†ìœ¼ë©´ Enter): ").strip()
    color = input("3ï¸ì›í•˜ëŠ” ìƒ‰ìƒì´ ìžˆìœ¼ì‹ ê°€ìš”? (ì˜ˆ: BLACK, ì—†ìœ¼ë©´ Enter): ").strip()

    recommended = recommend_with_filters(query, top_n=5, brand_filter=brand if brand else None, color_filter=color if color else None)
    print("\n[ìš”êµ¬ ì‚¬í•­]")
    print(f"{query}")
    print("\n[brand]")
    print(f"{brand}")
    print('\n[color]')
    print(f'{color}')
    print("\n[ì¶”ì²œ ê²°ê³¼]")
    print(recommended[['product_name', 'brand_name', 'grade', 'product_color', 'similarity']])
for name in recommended['product_name']:
    print(f"\nì œí’ˆëª…: {name}")
    print(product_reviews.loc[product_reviews['product_name'] == name, 'review_contents'].values[0])
- ë°œë³¼ì´ ë„“ì€ ì‹ ë°œì„ ì¶”ì²œë°›ê¸¸ ì›í–ˆìœ¼ë‚˜, 3ë²ˆì§¸ ì‹ ë°œ ê°™ì€ ê²½ìš° ë°œë³¼ì´ ì¢ì€ ë“¯í•˜ë‹¤ëŠ” ë¦¬ë·°ì—ë„ 'ë°œë³¼'ë•Œë¬¸ì— ì¶”ì²œ í•´ì¤Œ.
    - TF-IDFëŠ” ë‹¨ìˆœí•œ ë¹ˆë„ ê¸°ë°˜ì˜ ê°€ì¤‘ì¹˜ë¡œ ë§Œë“œëŠ” ëª¨ë¸
    - ë¬¸ë§¥ì„ ì´í•´í•  ìˆ˜ ìžˆëŠ” ëª¨ë¸ì„ ì°¾ì•„ì•¼í•¨
## 5-2. TF-IDF + ê°ì„±ëª¨ë¸
- KoBertë¡œ ë¦¬ë·°ì— ëŒ€í•´ ê°ì„± ë¶„ì„ ìˆ˜í–‰
    - positive ë¦¬ë·°ë§Œ í•„í„°ë§
    - í•„í„°ë§ëœ ê¸ì • ë¦¬ë·°ë§Œ ì œí’ˆë³„ë¡œ í•©ì¹¨
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from konlpy.tag import Okt
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F
# í˜•íƒœì†Œ ë¶„ì„ê¸° ë° ë¶ˆìš©ì–´ ë¶ˆëŸ¬ì˜¤ê¸°
okt = Okt()
with open('stopwords.txt', encoding='utf-8') as f:
    stopwords = set(line.strip() for line in f if line.strip())

# ê°ì„± ë¶„ì„ê¸° ë¡œë“œ (Huggingface KoBERT ê¸°ë°˜)
tokenizer = AutoTokenizer.from_pretrained("beomi/kcbert-base")
model = AutoModelForSequenceClassification.from_pretrained("beomi/kcbert-base", num_labels=2)

def predict_sentiment(text):
    if pd.isnull(text) or not isinstance(text, str):
        return None
    try:
        inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
        with torch.no_grad():
            outputs = model(**inputs)
            probs = F.softmax(outputs.logits, dim=1)
            label = torch.argmax(probs, dim=1).item()
        return 'positive' if label == 1 else 'negative'
    except:
        return None

# í˜•íƒœì†Œ ë¶„ì„ + ë¶ˆìš©ì–´ ì œê±° í•¨ìˆ˜
def clean_korean_text(text):
    if pd.isnull(text):
        return ''
    tokens = okt.morphs(text, stem=True)
    clean_tokens = [t for t in tokens if t not in stopwords and len(t) > 1]
    return ' '.join(clean_tokens)
# 1. ë¦¬ë·°ì— ê°ì„± ë¶„ì„ ì ìš©
tf_idf_shoes_df['sentiment'] = tf_idf_shoes_df['review_contents'].apply(predict_sentiment)

# 2. ê¸ì • ë¦¬ë·°ë§Œ í•„í„°ë§
positive_df = tf_idf_shoes_df[tf_idf_shoes_df['sentiment'] == 'positive']

# 3. ì œí’ˆë³„ ê¸ì • ë¦¬ë·° í†µí•© ë° ì •ì œ
product_reviews = positive_df.groupby('product_name')['review_contents'].apply(lambda x: ' '.join(x.dropna())).reset_index()
product_reviews['cleaned_review'] = product_reviews['review_contents'].apply(clean_korean_text)

# 4. TF-IDF ë²¡í„°í™”
vectorizer = TfidfVectorizer(max_features=5000)
review_tfidf_matrix = vectorizer.fit_transform(product_reviews['cleaned_review'])
# 5. ì¶”ì²œ í•¨ìˆ˜ ì •ì˜ (í•„í„° í¬í•¨)
def recommend_with_filters_and_sentiment(query, top_n=5, brand_filter=None, color_filter=None):
    query_clean = clean_korean_text(query)
    query_vec = vectorizer.transform([query_clean])
    similarity_scores = cosine_similarity(query_vec, review_tfidf_matrix).flatten()
    product_reviews['similarity'] = similarity_scores

    # í•„í„°ë§
    filtered = product_reviews.copy()
    if brand_filter:
        filtered = filtered.merge(tf_idf_shoes_df[['product_name', 'brand_name']].drop_duplicates(), on='product_name')
        filtered = filtered[filtered['brand_name'].str.contains(brand_filter, case=False, na=False)]
    if color_filter:
        filtered = filtered.merge(tf_idf_shoes_df[['product_name', 'product_color']].drop_duplicates(), on='product_name')
        filtered = filtered[filtered['product_color'].str.contains(color_filter, case=False, na=False)]

    top_indices = filtered.sort_values('similarity', ascending=False).head(top_n).index
    result = filtered.loc[top_indices]

    # ìƒì„¸ ì •ë³´ ê²°í•©
    final = result.merge(tf_idf_shoes_df[['product_name', 'brand_name', 'grade', 'product_color']].drop_duplicates(), on='product_name')
    return final[['product_name', 'brand_name', 'grade', 'product_color', 'similarity']]

# 6. ì‚¬ìš©ìž ìž…ë ¥ ê¸°ë°˜ ì¶”ì²œ ì‹¤í–‰
if __name__ == "__main__":
    print("ðŸ” ì‹ ë°œ ë¦¬ë·° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œìž…ë‹ˆë‹¤.\n")

    query = input("1. ì–´ë–¤ ì‹ ë°œì„ ì°¾ê³  ê³„ì‹ ê°€ìš”? (ì˜ˆ: í­ì‹ í•˜ê³  ë°œë³¼ì´ ë„“ì€ ì‹ ë°œ): ")
    brand = input("2. ì„ í˜¸ ë¸Œëžœë“œê°€ ìžˆìœ¼ì‹ ê°€ìš”? (ì˜ˆ: VANS, ì—†ìœ¼ë©´ Enter): ").strip()
    color = input("3. ì›í•˜ëŠ” ìƒ‰ìƒì´ ìžˆìœ¼ì‹ ê°€ìš”? (ì˜ˆ: BLACK, ì—†ìœ¼ë©´ Enter): ").strip()

    recommended = recommend_with_filters_and_sentiment(
        query, top_n=5,
        brand_filter=brand if brand else None,
        color_filter=color if color else None
    )

    print("\nâœ… [ì¶”ì²œ ê²°ê³¼]")
    print(recommended)
for name in recommended['product_name']:
    print(f"\nì œí’ˆëª…: {name}")
    print(product_reviews.loc[product_reviews['product_name'] == name, 'review_contents'].values[0])
# 6. WordCloud
### 6-1. í‰ì ë³„ WordCloud
- ì •ì„±ì  ë¶„ì„
- ì‹œê°í™”ë¥¼ í†µí•´ ì–´ë–¤ ì£¼ì œê°€ ìžì£¼ ì–¸ê¸‰ë˜ëŠ”ì§€ íŒŒì•…ì´ ê°€ëŠ¥
# !pip install wordcloud matplotlib pandas
from wordcloud import WordCloud
# í‰ì  ê¸°ì¤€ìœ¼ë¡œ ê¸ì •(4~5), ë¶€ì •(1~2), ì¤‘ê°„(3)ìœ¼ë¡œ ë¶„ë¦¬
positive_reviews = tf_idf_shoes_df[tf_idf_shoes_df['grade'] >= 4 ]['review_contents']
negative_reviews = tf_idf_shoes_df[(tf_idf_shoes_df['grade'] >= 1) & (tf_idf_shoes_df['grade'] <= 2) ]['review_contents']
mid_reviews = tf_idf_shoes_df[tf_idf_shoes_df['grade'] == 3]['review_contents']
zero_reviews = tf_idf_shoes_df[tf_idf_shoes_df['grade'] == 0]['review_contents']
print(len(positive_reviews))
print(len(negative_reviews))
print(len(mid_reviews))
print(len(zero_reviews))
positive_reviews
# í•˜ë‚˜ì˜ ê¸´ ë¬¸ìž¥ìœ¼ë¡œ join7
pos_text = " ".join(positive_reviews.astype(str))
neg_text = " ".join(negative_reviews.astype(str))
mid_text = " ".join(mid_reviews.astype(str))
zero_text = " ".join(zero_reviews.astype(str))
# í°íŠ¸ í™•ì¸
import os

fonts_dir = "C:\\Windows\\Fonts"

keywords = ["nanum", "ê³ ë”•", "gulim", "malgun", "batang", "dotum", "í•œê¸€"]  # ì£¼ìš” í•œê¸€ í°íŠ¸ í‚¤ì›Œë“œ

for font in os.listdir(fonts_dir):
    if font.lower().endswith(".ttf") and any(keyword.lower() in font.lower() for keyword in keywords):
        print(font)
def draw_wordcloud(text, title):
    wc = WordCloud(font_path="C:\\Windows\\Fonts\\malgun.ttf",  # í•œê¸€ í°íŠ¸ ê²½ë¡œ í•„ìš”
                   background_color="white",
                   width=800,
                   height=400).generate(text)

    plt.figure(figsize=(10, 5))
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    plt.title(title, fontsize=16)
    plt.show()
draw_wordcloud(pos_text, "ê¸ì • ë¦¬ë·° (í‰ì  4~5) WordCloud")
- ì£¼ìš” ë‹¨ì–´: ì‹ ë°œ, ì¢‹ì•„ìš”, ì´ë»ìš”, ì¶”ì²œ, ì •ë§, ë§Žì´, ìƒê°ë³´ë‹¤, ì¢‹ìŠµë‹ˆë‹¤. 
draw_wordcloud(neg_text, "ë¶€ì • ë¦¬ë·° (í‰ì  1~2) WordCloud")
- ì£¼ìš” ë‹¨ì–´: ê·¸ëƒ¥, ì‹ ë°œ, ë„ˆë¬´, ì¢€, ë°œë³¼ì´, êµí™˜, ì •ë§ ë“±
draw_wordcloud(neg_text, "ì¤‘ê°„ ë¦¬ë·° (í‰ì  3) WordCloud")
- ê·¸ëƒ¥, êµí™˜, ì •ë§, ì‚¬ì´ì¦ˆ, 
draw_wordcloud(zero_text, "ì œë¡œ ë¦¬ë·° (í‰ì  0) WordCloud")
- ì €ë ´í•œ, ë¬¼ê±´, ê°€ê²©ì—, ì •ë§
### 6-2. í‰ì ë³„ WordCloud (okt)
# !pip install konlpy
from konlpy.tag import Okt
def preprocess_text_with_okt(text_series):
    okt = Okt()
    nouns = []

    for sentence in text_series.dropna():  # NaN ì œê±°
        try:
            nouns += okt.nouns(str(sentence))  # ë¬¸ìž¥ë§ˆë‹¤ ëª…ì‚¬ ì¶”ì¶œ
        except:
            continue

    return " ".join(nouns)  # ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìœ„í•´ ë¬¸ìžì—´ë¡œ ê²°í•©
def draw_wordcloud(text, title):
    wc = WordCloud(
        font_path="C:\\Windows\\Fonts\\malgun.ttf",  
        background_color="white",
        width=800,
        height=400
    ).generate(text)

    plt.figure(figsize=(10, 5))
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    plt.title(title, fontsize=16)
    plt.show()
# Okt ê¸°ë°˜ ëª…ì‚¬ ì¶”ì¶œ í›„ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
pos_text_okt = preprocess_text_with_okt(positive_reviews)

# WordCloud ì¶œë ¥
draw_wordcloud(pos_text_okt, "ê¸ì • ë¦¬ë·° (í‰ì  4~5) - Okt ëª…ì‚¬ ê¸°ë°˜ WordCloud")
- ì •ì‚¬ì´ì¦ˆ, ì°©ìš©ê°, ë””ìžì¸, ì‹ ë°œ, ìƒê°, ì‹ ê³ ?
neg_text_okt = preprocess_text_with_okt(negative_reviews)
draw_wordcloud(neg_text_okt, "ë¶€ì • ë¦¬ë·° (í‰ì  1~2) - Okt ëª…ì‚¬ ê¸°ë°˜ WordCloud")
- ì‹ ë°œ, êµí™˜, ë°°ì†¡, ìƒí’ˆ, ì‚¬ì´ì¦ˆ, ë°˜í’ˆ, ë§¤ìž¥, ë¶ˆëŸ‰, ê·¸ëƒ¥, í™˜ë¶ˆ, ìƒíƒœ ...
mid_text_okt = preprocess_text_with_okt(mid_reviews)
draw_wordcloud(mid_text_okt, "ì¤‘ê°„ ë¦¬ë·° (í‰ì  3) - Okt ëª…ì‚¬ ê¸°ë°˜ WordCloud")
- ì‚¬ì´ì¦ˆ, ì‹ ã„´ë°œ, ë°°ì†¡, ë°œë³¼, ì¡°ê¸ˆ, ì‹ ê³ , ì¢€, êµ¬ë§¤
zero_text_okt = preprocess_text_with_okt(zero_reviews)
draw_wordcloud(zero_text_okt, "ì œë¡œ ë¦¬ë·° (í‰ì  0) - Okt ëª…ì‚¬ ê¸°ë°˜ WordCloud")
- ì •ë§, ë»‘ë»‘, ê°€ê²©, ë¬¼ê±´, ì²˜ìŒ, ë””ìžì¸
